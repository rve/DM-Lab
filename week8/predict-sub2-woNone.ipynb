{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((301619, 62), (148560, 62))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualization part\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "\n",
    "#basic libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "\n",
    "train_=pd.read_csv('../train_allcols.csv')\n",
    "validate_=pd.read_csv('../validate_allcols.csv')\n",
    "#test=pd.read_csv('../testwDSM.csv')\n",
    "\n",
    "train_.shape, validate_.shape, #test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((301619, 62),)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train.describe()\n",
    "train = train_.sample(10000)\n",
    "validate = validate_.sample(3000)\n",
    "train_.shape, #validate_.shape, validate.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4792, 62)\n",
      "4     1681\n",
      "2     1389\n",
      "3      809\n",
      "7      392\n",
      "10     372\n",
      "5      149\n",
      "Name: SUB2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train = train.query('SUB2 != 1')\n",
    "validate = validate.query('SUB2 != 1')\n",
    "\n",
    "train = train[train.SUB2.isin([2,3,4,5,7,10])]\n",
    "validate = validate[validate.SUB2.isin([2,3,4,7,10])]\n",
    "print train.shape\n",
    "print train['SUB2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score: 1.00t for feature VET\n",
      "F-score: 1.06t for feature ARRESTS\n",
      "F-score: 1.36t for feature PREG\n",
      "F-score: 1.40t for feature DAYWAIT\n",
      "F-score: 2.51t for feature ETHNIC\n",
      "F-score: 2.82t for feature CBSA10\n",
      "F-score: 2.89t for feature SUB3\n",
      "F-score: 4.50t for feature PRIMINC\n",
      "F-score: 4.56t for feature STFIPS\n",
      "F-score: 5.18t for feature RACE\n",
      "F-score: 5.27t for feature PRIMPAY\n",
      "F-score: 5.66t for feature ROUTE3\n",
      "F-score: 5.72t for feature DETNLF\n",
      "F-score: 7.69t for feature LIVARAG\n",
      "F-score: 8.13t for feature REGION\n",
      "F-score: 8.25t for feature PSYPROB\n",
      "F-score: 9.47t for feature EMPLOY\n",
      "F-score: 9.68t for feature GENDER\n",
      "F-score: 9.86t for feature YEAR\n",
      "F-score: 10.02t for feature CASEID\n",
      "F-score: 10.44t for feature MARSTAT\n",
      "F-score: 10.77t for feature FRSTUSE1\n",
      "F-score: 14.23t for feature FRSTUSE3\n",
      "F-score: 14.37t for feature EDUC\n",
      "F-score: 15.59t for feature HLTHINS\n",
      "F-score: 17.53t for feature DIVISION\n",
      "F-score: 18.86t for feature SERVSETA\n",
      "F-score: 19.26t for feature DETCRIM\n",
      "F-score: 20.49t for feature FREQ3\n",
      "F-score: 20.53t for feature FREQ2\n",
      "F-score: 20.89t for feature NUMSUBS\n",
      "F-score: 22.18t for feature FREQ1\n",
      "F-score: 23.51t for feature METHUSE\n",
      "F-score: 26.48t for feature PSOURCE\n",
      "F-score: 27.44t for feature ROUTE1\n",
      "F-score: 28.04t for feature SUB1\n",
      "F-score: 28.06t for feature NOPRIOR\n",
      "F-score: 54.07t for feature AGE\n",
      "F-score: 55.37t for feature DSMCRIT\n",
      "F-score: 63.80t for feature IDU\n",
      "F-score: 240.04t for feature ALCDRUG\n",
      "F-score: 291.15t for feature ROUTE2\n",
      "F-score: 332.76t for feature FRSTUSE2\n"
     ]
    }
   ],
   "source": [
    "# for sub2\n",
    "\n",
    "\n",
    "\n",
    "X_train = train.drop(['SUB2'], axis=1)\n",
    "Y_train = train[\"SUB2\"]\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "from sklearn.feature_selection import f_classif,chi2\n",
    "#Selector_f = SelectPercentile(f_classif, percentile=25)\n",
    "Selector_f = SelectKBest(f_classif, k=10)\n",
    "Selector_f.fit(X_train,Y_train)\n",
    "\n",
    "zipped = zip(X_train.columns.tolist(),Selector_f.scores_)\n",
    "ans = sorted(zipped, key=lambda x: x[1])\n",
    "for n,s in ans:    \n",
    "    if 'FLG' in n: \n",
    "        pass\n",
    "    else:\n",
    "        print 'F-score: %3.2ft for feature %s' % (s,n)\n",
    "                \n",
    "#print X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'VET','ARRESTS','PREG','DAYWAIT','ETHNIC','CBSA10','SUB3','PRIMINC','STFIPS','RACE','PRIMPAY','ROUTE3','DETNLF','LIVARAG','REGION','PSYPROB','EMPLOY','GENDER','YEAR','CASEID','MARSTAT','FRSTUSE1','FRSTUSE3','EDUC','HLTHINS','DIVISION','SERVSETA','DETCRIM','FREQ3','FREQ2','NUMSUBS','FREQ1','METHUSE','PSOURCE','ROUTE1','SUB1','NOPRIOR','AGE','DSMCRIT','IDU','ALCDRUG','ROUTE2','FRSTUSE2',"
     ]
    }
   ],
   "source": [
    "# get the sorted feature list\n",
    "import sys\n",
    "for n, s in ans:\n",
    "    \n",
    "    if 'FLG' in n: \n",
    "        pass\n",
    "    else:\n",
    "        sys.stdout.write('\\'%s\\',' % (n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4792, 23), (1369, 23))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train = train.query('SUB1 <= 10').query('SUB2 <= 10')\n",
    "#validate = validate.query('SUB1 <= 10').query('SUB2 <= 10')\n",
    "\n",
    "drop_list = ['SUB2',  'ROUTE2', 'FREQ2', 'FRSTUSE2', 'SUB3', 'ROUTE3', 'FREQ3', 'FRSTUSE3', 'NUMSUBS'\n",
    "             ]\n",
    "retain_list = ['EMPLOY','GENDER','FREQ1','YEAR','EDUC','PSYPROB','PSOURCE','SERVSETA','DETCRIM',\n",
    "               'REGION','NOPRIOR','DIVISION','DSMCRIT','ROUTE1','SUB1','AGE','IDU','SUB3','ROUTE3',\n",
    "               'FREQ3','FRSTUSE3','FREQ2','FRSTUSE2']\n",
    "X_train = train[retain_list]\n",
    "Y_train = train[\"SUB2\"]\n",
    "X_validate = validate[retain_list]\n",
    "Y_validate = validate[\"SUB2\"]\n",
    "#X_test  = test.drop(drop_list, axis=1)\n",
    "X_train.shape, X_validate.shape, #X_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EMPLOY', 'GENDER', 'FREQ1', 'YEAR', 'EDUC', 'PSYPROB', 'PSOURCE', 'SERVSETA', 'DETCRIM', 'REGION', 'NOPRIOR', 'DIVISION', 'DSMCRIT', 'ROUTE1', 'SUB1', 'AGE', 'IDU', 'SUB3', 'ROUTE3', 'FREQ3', 'FRSTUSE3', 'FREQ2', 'FRSTUSE2']\n"
     ]
    }
   ],
   "source": [
    "print X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4792, 183), (1369, 183))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one hot\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# 1. INSTANTIATE\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "\n",
    "# 2. FIT\n",
    "enc.fit(X_train)\n",
    "\n",
    "# 3. Transform\n",
    "onehotlabels = enc.transform(X_train).toarray()\n",
    "#onehotlabels.shape\n",
    "X_train = onehotlabels\n",
    "\n",
    "onehotlabels = enc.transform(X_validate).toarray()\n",
    "X_validate = onehotlabels\n",
    "\n",
    "X_train.shape, X_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.66\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "#Y_pred = logreg.predict(X_test)\n",
    "acc_log = round(logreg.score(X_validate, Y_validate) * 100, 2)\n",
    "print acc_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arc/Codes/DM-Lab/dmlab/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Perceptron\n",
    "\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, Y_train)\n",
    "#Y_pred = perceptron.predict(X_test)\n",
    "acc_perceptron = round(perceptron.score(X_validate, Y_validate) * 100, 2)\n",
    "print acc_perceptron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arc/Codes/DM-Lab/dmlab/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, Y_train)\n",
    "#Y_pred = sgd.predict(X_test)\n",
    "acc_sgd = round(sgd.score(X_validate, Y_validate) * 100, 2)\n",
    "print acc_sgd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.47\n"
     ]
    }
   ],
   "source": [
    "# Random Forest (slow)\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "#Y_pred = random_forest.predict(X_test)\n",
    "random_forest.score(X_train, Y_train)\n",
    "acc_random_forest = round(random_forest.score(X_validate, Y_validate) * 100, 2)\n",
    "print acc_random_forest\n",
    "\n",
    "#print cross_val_score(random_forest, X_validate, Y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.87\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier,\\\n",
    " AdaBoostClassifier, RandomForestClassifier\n",
    "#Adaboost \n",
    "ada_boost = AdaBoostClassifier(random_state=1851)\n",
    "ada_boost.fit(X_train, Y_train) \n",
    "\n",
    "acc_ada = round(ada_boost.score(X_validate, Y_validate) * 100, 2)\n",
    "print acc_ada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.57\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, Y_train)\n",
    "#Y_pred = sgd.predict(X_test)\n",
    "acc_sgd = round(sgd.score(X_validate, Y_validate) * 100, 2)\n",
    "print acc_sgd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.52\n"
     ]
    }
   ],
   "source": [
    "# Linear SVC\n",
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(X_train, Y_train)\n",
    "#Y_pred = linear_svc.predict(X_test)\n",
    "acc_linear_svc = round(linear_svc.score(X_validate, Y_validate) * 100, 2)\n",
    "print acc_linear_svc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict-sub2-woflags-newsplit-sample20000\n",
      "                        Model  Validate Set Score\n",
      "0         Logistic Regression               68.66\n",
      "4                  Linear SVC               68.52\n",
      "1               Random Forest               66.47\n",
      "3  Stochastic Gradient Decent               64.57\n",
      "5                    AdaBoost               61.87\n",
      "2                  Perceptron               60.34\n"
     ]
    }
   ],
   "source": [
    "print 'predict-sub2-woflags-newsplit-sample20000'\n",
    "models = pd.DataFrame({\n",
    "    'Model': [ 'Logistic Regression', \n",
    "              'Random Forest',  'Perceptron', \n",
    "              'Stochastic Gradient Decent', 'Linear SVC', \n",
    "               'AdaBoost'],\n",
    "    'Validate Set Score': [acc_log, \n",
    "              acc_random_forest,  acc_perceptron, \n",
    "              acc_sgd, acc_linear_svc, acc_ada]\n",
    "    })\n",
    "print models.sort_values(by='Validate Set Score', ascending=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
